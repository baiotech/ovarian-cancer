{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "biomarkers_cancer.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "zkbNTQR_xSKi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "labels = []\n",
        "markers = []\n",
        "early_late = []\n",
        "\n",
        "train_labels = []\n",
        "train_markers = []\n",
        "train_early_late = []\n",
        "\n",
        "val_labels = []\n",
        "val_markers = []\n",
        "val_early_late = []\n",
        "\n",
        "test_labels = []\n",
        "test_markers = []\n",
        "test_early_late = []\n",
        "\n",
        "def split_train_val_test(x):\n",
        "  train = x[:560]\n",
        "  val = x[560:720]\n",
        "  test = x[720:]\n",
        "  return train, val, test\n",
        "\n",
        "with open('ovarian_cancer.csv') as csvfile:\n",
        "  reader = csv.reader(csvfile, delimiter=';')\n",
        "  for row in reader:\n",
        "    labels.append(row[1])\n",
        "    markers.append(row[4:])\n",
        "    early_late.append(row[2])\n",
        "    # train_test.append(row[3])\n",
        "    \n",
        "for i in range(len(markers)):\n",
        "  for j in range(len(markers[i])):\n",
        "    if (markers[i][j] == 'NA' or markers[i][j] == ''):\n",
        "      markers[i][j] = 0\n",
        "\n",
        "train_labels, val_labels, test_labels = split_train_val_test(labels)\n",
        "train_markers, val_markers, test_markers = split_train_val_test(markers)\n",
        "train_early_late, val_early_late, test_early_late = split_train_val_test(early_late)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zqZF50Qd0mx1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import svm\n",
        "\n",
        "def format_labels(lbls):\n",
        "  # return [1 if label == 'Case' else 0 for label in lbls]\n",
        "  return [2 if label == '1' else 1 if label == '0' else 0 for label in lbls]\n",
        "\n",
        "# train_labels_formatted = format_labels(train_labels)\n",
        "# val_labels_formatted = format_labels(val_labels)\n",
        "# test_labels_formatted = format_labels(test_labels)\n",
        "\n",
        "train_labels_formatted = format_labels(train_early_late)\n",
        "val_labels_formatted = format_labels(val_early_late)\n",
        "test_labels_formatted = format_labels(test_early_late)\n",
        "\n",
        "# markers_of_interest = []\n",
        "\n",
        "# for i in range(len(np.array(train_markers).T.tolist())):\n",
        "#   marker = np.array(train_markers)[:, i]\n",
        "#   clf = svm.SVC(gamma='scale')\n",
        "#   clf.fit(marker.reshape(-1, 1), train_labels_formatted)\n",
        "#   score = sum([clf.predict(np.array(val_markers[j][i]).reshape(-1, 1))[0] == val_labels_formatted[j] for j in range(len(val_markers))]) / len(val_markers)\n",
        "#   if score > 0.85:\n",
        "#     score_test = sum([clf.predict(np.array(test_markers[j][i]).reshape(-1, 1))[0] == test_labels_formatted[j] for j in range(len(test_markers))]) / len(test_markers)\n",
        "#     print('success', i, score, score_test)\n",
        "#     markers_of_interest.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z8vjt-feH-WR",
        "colab_type": "code",
        "outputId": "b88ba21a-45e8-4a52-b8d4-fca27a128c89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "clf = svm.SVC(gamma='scale')\n",
        "clf.fit(train_markers, train_labels_formatted)\n",
        "score = sum([clf.predict(np.array(val_markers[j]).reshape(1, -1)) == val_labels_formatted[j] for j in range(len(val_markers))]) / len(val_markers)\n",
        "print(score)\n",
        "score_test = sum([clf.predict(np.array(test_markers[j]).reshape(1, -1)) == test_labels_formatted[j] for j in range(len(test_markers))]) / len(test_markers)\n",
        "print(score_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.875]\n",
            "[0.8875]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "j4cyjyDFOktZ",
        "colab_type": "code",
        "outputId": "571d0348-397b-4ace-a74e-bdf6efd9469b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "early_total = sum([val_early_late[j] == \"0\" for j in range(len(val_early_late))])\n",
        "late_total = sum([val_early_late[j] == \"1\" for j in range(len(val_early_late))])\n",
        "healthy_total = len(val_early_late) - early_total - late_total\n",
        "\n",
        "early_acc = sum([clf.predict(np.array(val_markers[j]).reshape(1, -1)) == val_labels_formatted[j] and val_early_late[j] == \"0\" for j in range(len(val_markers))]) / early_total\n",
        "late_acc = sum([clf.predict(np.array(val_markers[j]).reshape(1, -1)) == val_labels_formatted[j] and val_early_late[j] == \"1\" for j in range(len(val_markers))]) / late_total\n",
        "healthy_acc = sum([clf.predict(np.array(val_markers[j]).reshape(1, -1)) == val_labels_formatted[j] and val_early_late[j] == \"NA\" for j in range(len(val_markers))]) / healthy_total\n",
        "\n",
        "print(early_total, late_total, healthy_total)\n",
        "print(early_acc, late_acc, healthy_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16 16 128\n",
            "[0.] [0.75] [1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Dg9HHvCSSDhV",
        "colab_type": "code",
        "outputId": "bd392e20-a2b2-4132-badb-35373aeca86b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1057
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as utils\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters \n",
        "input_size = 61\n",
        "hidden_size = 30\n",
        "hidden_size2 = 10\n",
        "num_classes = 3\n",
        "num_epochs = 50\n",
        "batch_size = 80\n",
        "learning_rate = 0.001\n",
        "\n",
        "def to_tensor(data):\n",
        "  return torch.stack([torch.Tensor(np.array(i).astype(np.float)) for i in data])\n",
        "\n",
        "def to_tensor_y(data):\n",
        "  return torch.stack([torch.Tensor(np.array([i])).long() for i in data])\n",
        "\n",
        "tensor_x_train = to_tensor(train_markers)\n",
        "tensor_y_train = to_tensor_y(train_labels_formatted)\n",
        "\n",
        "tensor_x_val = to_tensor(val_markers)\n",
        "tensor_y_val = to_tensor_y(val_labels_formatted)\n",
        "\n",
        "tensor_x_test = to_tensor(test_markers)\n",
        "tensor_y_test = to_tensor_y(test_labels_formatted)\n",
        "\n",
        "train_dataset = utils.TensorDataset(tensor_x_train, tensor_y_train)\n",
        "val_dataset = utils.TensorDataset(tensor_x_val, tensor_y_val)\n",
        "test_dataset = utils.TensorDataset(tensor_x_test, tensor_y_test)\n",
        "\n",
        "train_loader = utils.DataLoader(train_dataset, batch_size=batch_size)\n",
        "val_loader = utils.DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_loader = utils.DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size2)\n",
        "        self.fc3 = nn.Linear(hidden_size2, num_classes)\n",
        "        self.softmax = nn.Softmax()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.softmax(out)\n",
        "        return out\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
        "\n",
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (xs, ys) in enumerate(train_loader):  \n",
        "        # Move tensors to the configured device\n",
        "        xs = xs.reshape(-1, 61).to(device)\n",
        "        ys = ys.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(xs)\n",
        "        loss = criterion(outputs, ys.view(-1))\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (i+1) % 5 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "            # Test the model\n",
        "            # In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for xs, ys in val_loader:\n",
        "        xs = xs.reshape(-1, 61).to(device)\n",
        "        ys = ys.to(device)\n",
        "        outputs = model(xs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        print(predicted)\n",
        "        total += ys.size(0)\n",
        "        correct += (predicted == ys).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the val patients: {} %'.format(correct / total))\n",
        "\n",
        "# Save the model checkpoint\n",
        "torch.save(model.state_dict(), 'model.ckpt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/50], Step [5/7], Loss: 2.3010\n",
            "Epoch [2/50], Step [5/7], Loss: 2.2825\n",
            "Epoch [3/50], Step [5/7], Loss: 2.2596\n",
            "Epoch [4/50], Step [5/7], Loss: 2.2336\n",
            "Epoch [5/50], Step [5/7], Loss: 2.2076\n",
            "Epoch [6/50], Step [5/7], Loss: 2.1816\n",
            "Epoch [7/50], Step [5/7], Loss: 2.1520\n",
            "Epoch [8/50], Step [5/7], Loss: 2.1153\n",
            "Epoch [9/50], Step [5/7], Loss: 2.0699\n",
            "Epoch [10/50], Step [5/7], Loss: 2.0161\n",
            "Epoch [11/50], Step [5/7], Loss: 1.9570\n",
            "Epoch [12/50], Step [5/7], Loss: 1.8978\n",
            "Epoch [13/50], Step [5/7], Loss: 1.8430\n",
            "Epoch [14/50], Step [5/7], Loss: 1.7950\n",
            "Epoch [15/50], Step [5/7], Loss: 1.7545\n",
            "Epoch [16/50], Step [5/7], Loss: 1.7210\n",
            "Epoch [17/50], Step [5/7], Loss: 1.6938\n",
            "Epoch [18/50], Step [5/7], Loss: 1.6720\n",
            "Epoch [19/50], Step [5/7], Loss: 1.6546\n",
            "Epoch [20/50], Step [5/7], Loss: 1.6408\n",
            "Epoch [21/50], Step [5/7], Loss: 1.6296\n",
            "Epoch [22/50], Step [5/7], Loss: 1.6203\n",
            "Epoch [23/50], Step [5/7], Loss: 1.6123\n",
            "Epoch [24/50], Step [5/7], Loss: 1.6049\n",
            "Epoch [25/50], Step [5/7], Loss: 1.5977\n",
            "Epoch [26/50], Step [5/7], Loss: 1.5905\n",
            "Epoch [27/50], Step [5/7], Loss: 1.5836\n",
            "Epoch [28/50], Step [5/7], Loss: 1.5773\n",
            "Epoch [29/50], Step [5/7], Loss: 1.5723\n",
            "Epoch [30/50], Step [5/7], Loss: 1.5677\n",
            "Epoch [31/50], Step [5/7], Loss: 1.5632\n",
            "Epoch [32/50], Step [5/7], Loss: 1.5593\n",
            "Epoch [33/50], Step [5/7], Loss: 1.5559\n",
            "Epoch [34/50], Step [5/7], Loss: 1.5529\n",
            "Epoch [35/50], Step [5/7], Loss: 1.5503\n",
            "Epoch [36/50], Step [5/7], Loss: 1.5479\n",
            "Epoch [37/50], Step [5/7], Loss: 1.5457\n",
            "Epoch [38/50], Step [5/7], Loss: 1.5436\n",
            "Epoch [39/50], Step [5/7], Loss: 1.5416\n",
            "Epoch [40/50], Step [5/7], Loss: 1.5398\n",
            "Epoch [41/50], Step [5/7], Loss: 1.5380\n",
            "Epoch [42/50], Step [5/7], Loss: 1.5363\n",
            "Epoch [43/50], Step [5/7], Loss: 1.5347\n",
            "Epoch [44/50], Step [5/7], Loss: 1.5332\n",
            "Epoch [45/50], Step [5/7], Loss: 1.5317\n",
            "Epoch [46/50], Step [5/7], Loss: 1.5303\n",
            "Epoch [47/50], Step [5/7], Loss: 1.5289\n",
            "Epoch [48/50], Step [5/7], Loss: 1.5276\n",
            "Epoch [49/50], Step [5/7], Loss: 1.5262\n",
            "Epoch [50/50], Step [5/7], Loss: 1.5249\n",
            "tensor([0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
            "        2, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0,\n",
            "        2, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "tensor([0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 2, 0, 0, 0,\n",
            "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0,\n",
            "        0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 2,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
            "Accuracy of the network on the val patients: 55.95 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6Rq9vERomIe9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}